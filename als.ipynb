{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load table into pandas df\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "ratings_df = pd.read_csv('sample_data/ratings.csv')\n",
    "\n",
    "print(ratings_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"MovieRecommendationALS\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(ratings_df, test_size=0.3, random_state=42) \n",
    "dev_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42) \n",
    "\n",
    "train_spark_df = spark.createDataFrame(train_df)\n",
    "dev_spark_df = spark.createDataFrame(dev_df)\n",
    "test_spark_df = spark.createDataFrame(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_ALS(train_data, validation_data, maxIter, regParam, rank):\n",
    "    # get ALS model\n",
    "    als = ALS(\n",
    "        maxIter=maxIter,\n",
    "        regParam=regParam,\n",
    "        rank=rank,\n",
    "        userCol=\"userId\",\n",
    "        itemCol=\"movieId\",\n",
    "        ratingCol=\"rating\",\n",
    "        coldStartStrategy=\"drop\")\n",
    "    # train ALS model\n",
    "    model = als.fit(train_data)\n",
    "    # evaluate the model by computing the RMSE on the validation data\n",
    "    predictions = model.transform(validation_data)\n",
    "    evaluator = RegressionEvaluator(metricName=\"mae\",\n",
    "                                    labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "    mae = evaluator.evaluate(predictions)\n",
    "    print(f\"{rank} latent factors, regularization = {regParam}, max iter = {maxIter}: validation MAE = {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in [10, 20]:\n",
    "  for reg in [0.01, 0.05, 0.1]:\n",
    "    for r in [10, 20, 50]:\n",
    "      tune_ALS(train_spark_df, dev_spark_df, iter, reg, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 latent factors, regularization = 0.01, max iter = 10: validation MAE = 0.8809409648936434\n",
    "# 20 latent factors, regularization = 0.01, max iter = 10: validation MAE = 0.9865915344359836\n",
    "# 50 latent factors, regularization = 0.01, max iter = 10: validation MAE = 1.092827599524713\n",
    "# 10 latent factors, regularization = 0.05, max iter = 10: validation MAE = 0.7407131944113025\n",
    "# 20 latent factors, regularization = 0.05, max iter = 10: validation MAE = 0.7574510508867892\n",
    "# 50 latent factors, regularization = 0.05, max iter = 10: validation MAE = 0.753138706570574\n",
    "# 10 latent factors, regularization = 0.1, max iter = 10: validation MAE = 0.6912527214782043 <- Best\n",
    "# 20 latent factors, regularization = 0.1, max iter = 10: validation MAE = 0.6950250406099087\n",
    "# 50 latent factors, regularization = 0.1, max iter = 10: validation MAE = 0.6919204329948865 \n",
    "# 10 latent factors, regularization = 0.01, max iter = 20: validation MAE = 0.892745112963494\n",
    "# 20 latent factors, regularization = 0.01, max iter = 20: validation MAE = 0.9969077982169593\n",
    "# 50 latent factors, regularization = 0.01, max iter = 20: validation MAE = 1.0373869455851963\n",
    "# 10 latent factors, regularization = 0.05, max iter = 20: validation MAE = 0.734153067477066\n",
    "# 20 latent factors, regularization = 0.05, max iter = 20: validation MAE = 0.7456158548305457\n",
    "# 50 latent factors, regularization = 0.05, max iter = 20: validation MAE = 0.7354275553562601\n",
    "# 10 latent factors, regularization = 0.1, max iter = 20: validation MAE = 0.6899199263238752\n",
    "# 20 latent factors, regularization = 0.1, max iter = 20: validation MAE = 0.6942792276238924\n",
    "# 50 latent factors, regularization = 0.1, max iter = 20: validation MAE = 0.6921828139817162 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ALS(train_data, test_data):\n",
    "    # get ALS model\n",
    "    als = ALS(\n",
    "        maxIter=10,\n",
    "        regParam=0.1,\n",
    "        rank=10,\n",
    "        userCol=\"userId\",\n",
    "        itemCol=\"movieId\",\n",
    "        ratingCol=\"rating\",\n",
    "        coldStartStrategy=\"drop\")\n",
    "    # train ALS model\n",
    "    model = als.fit(train_data)\n",
    "    # evaluate the model by computing the RMSE on the validation data\n",
    "    predictions = model.transform(test_data)\n",
    "    evaluator_mae = RegressionEvaluator(metricName=\"mae\",\n",
    "                                    labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "    evaluator_mse = RegressionEvaluator(metricName=\"mse\",\n",
    "                                    labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "    mae = evaluator_mae.evaluate(predictions)\n",
    "    mse = evaluator_mse.evaluate(predictions)\n",
    "\n",
    "    print(f\"MAE = {mae}, MSE = {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ALS(train_spark_df, test_spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE = 0.6899739807562887\n",
    "# MSE = 0.8052170727133248"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
